{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Agent Integrations \u00b6 Welcome to the wonderful world of developing Agent Integrations for Datadog. Here we document how we do things, the processes for various tasks, coding conventions & best practices, the internals of our testing infrastructure, and so much more. If you are intrigued, continue reading. If not, continue all the same Getting started \u00b6 To work on any integration, you must install the necessary tooling . After that you may immediately begin testing or read through the best practices we strive to follow. Also, feel free to check out how ddev works and browse the API reference of the base package.","title":"Home"},{"location":"#agent-integrations","text":"Welcome to the wonderful world of developing Agent Integrations for Datadog. Here we document how we do things, the processes for various tasks, coding conventions & best practices, the internals of our testing infrastructure, and so much more. If you are intrigued, continue reading. If not, continue all the same","title":"Agent Integrations"},{"location":"#getting-started","text":"To work on any integration, you must install the necessary tooling . After that you may immediately begin testing or read through the best practices we strive to follow. Also, feel free to check out how ddev works and browse the API reference of the base package.","title":"Getting started"},{"location":"setup/","text":"Setup \u00b6 This will be relatively painless, we promise! Python \u00b6 To work on any integration you must install Python 3.8+. After installation, restart your terminal and ensure that your newly installed Python comes first in your PATH . Windows \u00b6 Windows users have it the easiest. Simply download the latest x86-64 executable installer from https://www.python.org/downloads/windows and run it. When prompted, be sure to select the option to add to your PATH . Also, it is recommended that you choose the per-user installation method. Verify successful PATH modification: where python macOS \u00b6 We recommend using Homebrew . First update the formulae and Homebrew itself: brew update then either install Python: brew install python or upgrade it: brew upgrade python After it completes, check the output to see if it asked you to run any extra commands and if so, execute them. Verify successful PATH modification: which -a python Linux \u00b6 Ah, you enjoy difficult things. Are you using Gentoo? We recommend using either Miniconda or pyenv . Whatever you do, never modify the system Python. Verify successful PATH modification: which -a python ddev \u00b6 You have 2 options to install the CLI provided by the package datadog-checks-dev . Warning For either option, if you are on macOS/Linux do not use sudo ! Doing so will result in a broken installation. Development \u00b6 If you cloned integrations-core and want to always use the version based on the current branch, run: python -m pip install -e \"path/to/datadog_checks_dev[cli]\" Note Be aware that this method does not keep track of dependencies so you will need to re-run the command if/when the required dependencies are changed. Stable \u00b6 The latest released version may be installed from PyPI : python -m pip install --upgrade \"datadog-checks-dev[cli]\" Docker \u00b6 Docker is used in nearly every integration's test suite therefore we simply require it to avoid confusion. Windows Install Docker Desktop for Windows . Right-click the Docker taskbar item and update Settings > Shared Drives with any locations you need to open e.g. C:\\ . macOS Install Docker Desktop for Mac . Right-click the Docker taskbar item and update Preferences > File Sharing with any locations you need to open. Linux Install Docker Engine for your distribution: Distributions Ubuntu Docker CE for Ubuntu Debian Docker CE for Debian Fedora Docker CE for Fedora CentOS Docker CE for CentOS Add your user to the docker group: sudo usermod -aG docker $USER Sign out and then back in again so your changes take effect. After installation, restart your terminal one last time.","title":"Setup"},{"location":"setup/#setup","text":"This will be relatively painless, we promise!","title":"Setup"},{"location":"setup/#python","text":"To work on any integration you must install Python 3.8+. After installation, restart your terminal and ensure that your newly installed Python comes first in your PATH .","title":"Python"},{"location":"setup/#windows","text":"Windows users have it the easiest. Simply download the latest x86-64 executable installer from https://www.python.org/downloads/windows and run it. When prompted, be sure to select the option to add to your PATH . Also, it is recommended that you choose the per-user installation method. Verify successful PATH modification: where python","title":"Windows"},{"location":"setup/#macos","text":"We recommend using Homebrew . First update the formulae and Homebrew itself: brew update then either install Python: brew install python or upgrade it: brew upgrade python After it completes, check the output to see if it asked you to run any extra commands and if so, execute them. Verify successful PATH modification: which -a python","title":"macOS"},{"location":"setup/#linux","text":"Ah, you enjoy difficult things. Are you using Gentoo? We recommend using either Miniconda or pyenv . Whatever you do, never modify the system Python. Verify successful PATH modification: which -a python","title":"Linux"},{"location":"setup/#ddev","text":"You have 2 options to install the CLI provided by the package datadog-checks-dev . Warning For either option, if you are on macOS/Linux do not use sudo ! Doing so will result in a broken installation.","title":"ddev"},{"location":"setup/#development","text":"If you cloned integrations-core and want to always use the version based on the current branch, run: python -m pip install -e \"path/to/datadog_checks_dev[cli]\" Note Be aware that this method does not keep track of dependencies so you will need to re-run the command if/when the required dependencies are changed.","title":"Development"},{"location":"setup/#stable","text":"The latest released version may be installed from PyPI : python -m pip install --upgrade \"datadog-checks-dev[cli]\"","title":"Stable"},{"location":"setup/#docker","text":"Docker is used in nearly every integration's test suite therefore we simply require it to avoid confusion. Windows Install Docker Desktop for Windows . Right-click the Docker taskbar item and update Settings > Shared Drives with any locations you need to open e.g. C:\\ . macOS Install Docker Desktop for Mac . Right-click the Docker taskbar item and update Preferences > File Sharing with any locations you need to open. Linux Install Docker Engine for your distribution: Distributions Ubuntu Docker CE for Ubuntu Debian Docker CE for Debian Fedora Docker CE for Fedora CentOS Docker CE for CentOS Add your user to the docker group: sudo usermod -aG docker $USER Sign out and then back in again so your changes take effect. After installation, restart your terminal one last time.","title":"Docker"},{"location":"testing/","text":"Testing \u00b6 Basic \u00b6 List \u00b6 Coverage \u00b6 Style \u00b6 Benchmarks \u00b6 E2E \u00b6 List \u00b6 Start \u00b6 Stop \u00b6 Check \u00b6 Test \u00b6","title":"Testing"},{"location":"testing/#testing","text":"","title":"Testing"},{"location":"testing/#basic","text":"","title":"Basic"},{"location":"testing/#list","text":"","title":"List"},{"location":"testing/#coverage","text":"","title":"Coverage"},{"location":"testing/#style","text":"","title":"Style"},{"location":"testing/#benchmarks","text":"","title":"Benchmarks"},{"location":"testing/#e2e","text":"","title":"E2E"},{"location":"testing/#list_1","text":"","title":"List"},{"location":"testing/#start","text":"","title":"Start"},{"location":"testing/#stop","text":"","title":"Stop"},{"location":"testing/#check","text":"","title":"Check"},{"location":"testing/#test","text":"","title":"Test"},{"location":"base/about/","text":"About \u00b6 The package datadog-checks-base provides all the functionality and utilities necessary for writing Agent Integrations a.k.a. Checks. Most importantly it provides the AgentCheck base class from which every Check must be inherited. You would use it like so: from datadog_checks.base import AgentCheck class AwesomeCheck ( AgentCheck ): __NAMESPACE__ = 'awesome' def check ( self , instance ): self . gauge ( 'test' , 1.23 , tags = [ 'foo:bar' ]) The check method is what the Datadog Agent will execute. In this example we created a Check and gave it a namespace of awesome . This means that by default, every submission's name will be prefixed with awesome. . We submitted a gauge metric named awesome.test with a value of 1.23 tagged by foo:bar . The magic hidden by the usability of the API is that this actually calls a C binding which communicates with the Agent (written in Go).","title":"About"},{"location":"base/about/#about","text":"The package datadog-checks-base provides all the functionality and utilities necessary for writing Agent Integrations a.k.a. Checks. Most importantly it provides the AgentCheck base class from which every Check must be inherited. You would use it like so: from datadog_checks.base import AgentCheck class AwesomeCheck ( AgentCheck ): __NAMESPACE__ = 'awesome' def check ( self , instance ): self . gauge ( 'test' , 1.23 , tags = [ 'foo:bar' ]) The check method is what the Datadog Agent will execute. In this example we created a Check and gave it a namespace of awesome . This means that by default, every submission's name will be prefixed with awesome. . We submitted a gauge metric named awesome.test with a value of 1.23 tagged by foo:bar . The magic hidden by the usability of the API is that this actually calls a C binding which communicates with the Agent (written in Go).","title":"About"},{"location":"base/api/","text":"API \u00b6 AgentCheck \u00b6 class datadog_checks.base. AgentCheck ( *args , **kwargs ) The base class for any Agent based integration. In general, you don't need to and you should not override anything from the base class except the check method but sometimes it might be useful for a Check to have its own constructor. When overriding __init__ you have to remember that, depending on the configuration, the Agent might create several different Check instances and the method would be called as many times. Agent 6,7 signature: AgentCheck(name, init_config, instances) # instances contain only 1 instance AgentCheck.check(instance) Agent 8 signature: AgentCheck(name, init_config, instance) # one instance AgentCheck.check() # no more instance argument for check method Note when loading a Custom check, the Agent will inspect the module searching for a subclass of AgentCheck . If such a class exists but has been derived in turn, it'll be ignored - you should never derive from an existing Check . name ( str ) - the name of the check init_config ( dict ) - the init_config section of the configuration. instance ( List[dict] ) - a one-element list containing the instance options from the configuration file (a list is used to keep backward compatibility with older versions of the Agent). gauge ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a gauge metric. Parameters: name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix count ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a raw count metric. name ( str ) - the name of the metric value ( float ) - the value for the metric :param list tags: (optional) a list of tags to associate with this metric. hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix monotonic_count ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample an increasing counter metric. name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix rate ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a point, with the rate calculated at the end of the check. name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix histogram ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a histogram metric. name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix historate ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a histogram based on rate metrics. name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix service_check ( self , name , status , tags=None , hostname=None , message=None , raw=False ) Send the status of a service. name ( str ) - the name of the service check status ( int ) - a constant describing the service status. tags ( List[str]) ) - a list of tags to associate with this service check message ( str ) - additional information or a description of why this status occurred. raw ( bool ) - whether to ignore any defined namespace prefix event ( self , event ) Send an event. An event is a dictionary with the following keys and data types: { \"timestamp\" : int , # the epoch timestamp for the event \"event_type\" : str , # the event name \"api_key\" : str , # the api key for your account \"msg_title\" : str , # the title of the event \"msg_text\" : str , # the text body of the event \"aggregation_key\" : str , # a key to use for aggregating events \"alert_type\" : str , # (optional) one of ('error', 'warning', 'success', 'info'), defaults to 'info' \"source_type_name\" : str , # (optional) the source type name \"host\" : str , # (optional) the name of the host \"tags\" : list , # (optional) a list of tags to associate with this event \"priority\" : str , # (optional) specifies the priority of the event (\"normal\" or \"low\") } event ( dict ) - the event to be sent Stubs \u00b6 Aggregator \u00b6 class datadog_checks.base.stubs.aggregator. AggregatorStub ( ) Mainly used for unit testing checks, this stub makes possible to execute a check without a running Agent. assert_metric ( self , name , value=None , tags=None , count=None , at_least=1 , hostname=None , metric_type=None , device=None ) Assert a metric was processed by this stub assert_metric_has_tag ( self , metric_name , tag , count=None , at_least=1 ) Assert a metric is tagged with tag assert_metric_has_tag_prefix ( self , metric_name , tag_prefix , count=None , at_least=1 ) assert_service_check ( self , name , status=None , tags=None , count=None , at_least=1 , hostname=None , message=None ) Assert a service check was processed by this stub assert_event ( self , msg_text , count=None , at_least=1 , exact_match=True , tags=None , **kwargs ) assert_all_metrics_covered ( self ) assert_no_duplicate_metrics ( self ) Assert no duplicate metrics have been submitted. Metrics are considered duplicate when all following fields match: - metric name - type (gauge, rate, etc) - tags - hostname assert_no_duplicate_service_checks ( self ) Assert no duplicate service checks have been submitted. Service checks are considered duplicate when all following fields match: - metric name - status - tags - hostname assert_no_duplicate_all ( self ) Assert no duplicate metrics and service checks have been submitted. reset ( self ) Set the stub to its initial state Datadog Agent \u00b6 class datadog_checks.base.stubs.datadog_agent. DatadogAgentStub ( ) assert_metadata ( self , check_id , data ) assert_metadata_count ( self , count ) get_config ( self , *args , **kwargs ) get_hostname ( self ) get_version ( self ) log ( self , *args , **kwargs ) reset ( self ) set_check_metadata ( self , check_id , name , value ) set_external_tags ( self , *args , **kwargs ) tracemalloc_enabled ( self , *args , **kwargs )","title":"API"},{"location":"base/api/#api","text":"","title":"API"},{"location":"base/api/#agentcheck","text":"class datadog_checks.base. AgentCheck ( *args , **kwargs ) The base class for any Agent based integration. In general, you don't need to and you should not override anything from the base class except the check method but sometimes it might be useful for a Check to have its own constructor. When overriding __init__ you have to remember that, depending on the configuration, the Agent might create several different Check instances and the method would be called as many times. Agent 6,7 signature: AgentCheck(name, init_config, instances) # instances contain only 1 instance AgentCheck.check(instance) Agent 8 signature: AgentCheck(name, init_config, instance) # one instance AgentCheck.check() # no more instance argument for check method Note when loading a Custom check, the Agent will inspect the module searching for a subclass of AgentCheck . If such a class exists but has been derived in turn, it'll be ignored - you should never derive from an existing Check . name ( str ) - the name of the check init_config ( dict ) - the init_config section of the configuration. instance ( List[dict] ) - a one-element list containing the instance options from the configuration file (a list is used to keep backward compatibility with older versions of the Agent). gauge ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a gauge metric. Parameters: name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix count ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a raw count metric. name ( str ) - the name of the metric value ( float ) - the value for the metric :param list tags: (optional) a list of tags to associate with this metric. hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix monotonic_count ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample an increasing counter metric. name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix rate ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a point, with the rate calculated at the end of the check. name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix histogram ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a histogram metric. name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix historate ( self , name , value , tags=None , hostname=None , device_name=None , raw=False ) Sample a histogram based on rate metrics. name ( str ) - the name of the metric value ( float ) - the value for the metric tags ( List[str]) ) - a list of tags to associate with this metric hostname ( str ) - a hostname to associate with this metric. Defaults to the current host. device_name ( str ) - deprecated add a tag in the form device:<device_name> to the tags list instead. raw ( bool ) - whether to ignore any defined namespace prefix service_check ( self , name , status , tags=None , hostname=None , message=None , raw=False ) Send the status of a service. name ( str ) - the name of the service check status ( int ) - a constant describing the service status. tags ( List[str]) ) - a list of tags to associate with this service check message ( str ) - additional information or a description of why this status occurred. raw ( bool ) - whether to ignore any defined namespace prefix event ( self , event ) Send an event. An event is a dictionary with the following keys and data types: { \"timestamp\" : int , # the epoch timestamp for the event \"event_type\" : str , # the event name \"api_key\" : str , # the api key for your account \"msg_title\" : str , # the title of the event \"msg_text\" : str , # the text body of the event \"aggregation_key\" : str , # a key to use for aggregating events \"alert_type\" : str , # (optional) one of ('error', 'warning', 'success', 'info'), defaults to 'info' \"source_type_name\" : str , # (optional) the source type name \"host\" : str , # (optional) the name of the host \"tags\" : list , # (optional) a list of tags to associate with this event \"priority\" : str , # (optional) specifies the priority of the event (\"normal\" or \"low\") } event ( dict ) - the event to be sent","title":"AgentCheck"},{"location":"base/api/#stubs","text":"","title":"Stubs"},{"location":"base/api/#aggregator","text":"class datadog_checks.base.stubs.aggregator. AggregatorStub ( ) Mainly used for unit testing checks, this stub makes possible to execute a check without a running Agent. assert_metric ( self , name , value=None , tags=None , count=None , at_least=1 , hostname=None , metric_type=None , device=None ) Assert a metric was processed by this stub assert_metric_has_tag ( self , metric_name , tag , count=None , at_least=1 ) Assert a metric is tagged with tag assert_metric_has_tag_prefix ( self , metric_name , tag_prefix , count=None , at_least=1 ) assert_service_check ( self , name , status=None , tags=None , count=None , at_least=1 , hostname=None , message=None ) Assert a service check was processed by this stub assert_event ( self , msg_text , count=None , at_least=1 , exact_match=True , tags=None , **kwargs ) assert_all_metrics_covered ( self ) assert_no_duplicate_metrics ( self ) Assert no duplicate metrics have been submitted. Metrics are considered duplicate when all following fields match: - metric name - type (gauge, rate, etc) - tags - hostname assert_no_duplicate_service_checks ( self ) Assert no duplicate service checks have been submitted. Service checks are considered duplicate when all following fields match: - metric name - status - tags - hostname assert_no_duplicate_all ( self ) Assert no duplicate metrics and service checks have been submitted. reset ( self ) Set the stub to its initial state","title":"Aggregator"},{"location":"base/api/#datadog-agent","text":"class datadog_checks.base.stubs.datadog_agent. DatadogAgentStub ( ) assert_metadata ( self , check_id , data ) assert_metadata_count ( self , count ) get_config ( self , *args , **kwargs ) get_hostname ( self ) get_version ( self ) log ( self , *args , **kwargs ) reset ( self ) set_check_metadata ( self , check_id , name , value ) set_external_tags ( self , *args , **kwargs ) tracemalloc_enabled ( self , *args , **kwargs )","title":"Datadog Agent"},{"location":"base/databases/","text":"Databases \u00b6 The base class provides a standard way to define and collect data from arbitrary queries. All the functionality is exposed by the Query and QueryManager classes. Query \u00b6 class datadog_checks.base.utils.db. Query ( query_data ) This class accepts a single dict argument which is the necessary data to run the query. The representation is based on our custom_queries format originally designed and implemented way back in #1528 . It is now part of all our database integrations and other products have since adopted this idea. compile ( self , column_transformers , extra_transformers ) This will be called by QueryManager.compile_queries and should never be called directly. QueryManager \u00b6 class datadog_checks.base.utils.db. QueryManager ( check , executor , queries=None , tags=None , error_handler=None ) compile_queries ( self ) execute ( self ) execute_query ( self , query ) Transformers \u00b6 Column \u00b6 class datadog_checks.base.utils.db.transform. ColumnTransformers ( ) match This is used for querying unstructured data. For example, say you want to collect the fields named foo and bar . Typically, they would be stored like: | foo | bar | | --- | --- | | 4 | 2 | and would be queried like: SELECT foo , bar FROM ... Often, you will instead find data stored in the following format: | metric | value | | ------ | ----- | | foo | 4 | | bar | 2 | and would be queried like: SELECT metric , value FROM ... In this case, the metric column stores the name with which to match on and its value is stored in a separate column. The required items modifier is a mapping of matched names to column data values. Consider the values to be exactly the same as the entries in the columns top level field. You must also define a source modifier either for this transformer itself or in the values of items (which will take precedence). The source will be treated as the value of the match. Say this is your configuration: query : SELECT source1, source2, metric FROM TABLE columns : - name : value1 type : source - name : value2 type : source - name : metric_name type : match source : value1 items : foo : name : test.foo type : gauge source : value2 bar : name : test.bar type : monotonic_gauge and the result set is: | source1 | source2 | metric | | ------- | ------- | ------ | | 1 | 2 | foo | | 3 | 4 | baz | | 5 | 6 | bar | Here's what would be submitted: foo - test.foo as a gauge with a value of 2 bar - test.bar.total as a gauge and test.bar.count as a monotonic_count , both with a value of 5 baz - nothing since it was not defined as a match item monotonic_gauge Send the result as both a gauge suffixed by .total and a monotonic_count suffixed by .count . service_check Submit a service check. The required modifier status_map is a mapping of values to statuses. Valid statuses include: OK WARNING CRITICAL UNKNOWN Any encountered values that are not defined will be sent as UNKNOWN . tag Convert a column to a tag that will be used in every subsequent submission. For example, if you named the column env and the column returned the value prod1 , all submissions from that row will be tagged by env:prod1 . This also accepts an optional modifier called boolean that when set to true will transform the result to the string true or false . So for example if you named the column alive and the result was the number 0 the tag will be alive:false . temporal_percent Send the result as percentage of time since the last check run as a rate . For example, say the result is a forever increasing counter representing the total time spent pausing for garbage collection since start up. That number by itself is quite useless, but as a percentage of time spent pausing since the previous collection interval it becomes a useful metric. There is one required parameter called scale that indicates what unit of time the result should be considered. Valid values are: second millisecond microsecond nanosecond You may also define the unit as an integer number of parts compared to seconds e.g. millisecond is equivalent to 1000 . time_elapsed Send the number of seconds elapsed from a time in the past as a gauge . For example, if the result is an instance of datetime.datetime representing 5 seconds ago, then this would submit with a value of 5 . The optional modifier format indicates what format the result is in. By default it is native , assuming the underlying library provides timestamps as datetime objects. If it does not and passes them through directly as strings, you must provide the expected timestamp format using the supported codes . Note The code %z (lower case) is not supported on Windows. Extra \u00b6 Every column transformer (except tag ) is supported at this level, the only difference being one must set a source to retrieve the desired value. So for example here: columns : - name : foo.bar type : rate extras : - name : foo.current type : gauge source : foo.bar the metric foo.current will be sent as a gauge will the value of foo.bar . class datadog_checks.base.utils.db.transform. ExtraTransformers ( ) expression This allows the evaluation of a limited subset of Python syntax and built-in functions. columns : - name : disk.total type : gauge - name : disk.used type : gauge extras : - name : disk.free expression : disk.total - disk.used submit_type : gauge For brevity, if the expression attribute exists and type does not then it is assumed the type is expression . The submit_type can be any transformer and any extra options are passed down to it. The result of every expression is stored, so in lieu of a submit_type the above example could also be written as: columns : - name : disk.total type : gauge - name : disk.used type : gauge extras : - name : free expression : disk.total - disk.used - name : disk.free type : gauge source : free The order matters though, so for example the following will fail: columns : - name : disk.total type : gauge - name : disk.used type : gauge extras : - name : disk.free type : gauge source : free - name : free expression : disk.total - disk.used since the source free does not yet exist. percent Send a percentage based on 2 sources as a gauge . The required modifiers are part and total . For example, if you have this configuration: columns : - name : disk.total type : gauge - name : disk.used type : gauge extras : - name : disk.utilized type : percent part : disk.used total : disk.total then the extra metric disk.utilized would be sent as a gauge calculated as disk.used / disk.total * 100 . If the source of total is 0 , then the submitted value will always be sent as 0 too.","title":"Databases"},{"location":"base/databases/#databases","text":"The base class provides a standard way to define and collect data from arbitrary queries. All the functionality is exposed by the Query and QueryManager classes.","title":"Databases"},{"location":"base/databases/#query","text":"class datadog_checks.base.utils.db. Query ( query_data ) This class accepts a single dict argument which is the necessary data to run the query. The representation is based on our custom_queries format originally designed and implemented way back in #1528 . It is now part of all our database integrations and other products have since adopted this idea. compile ( self , column_transformers , extra_transformers ) This will be called by QueryManager.compile_queries and should never be called directly.","title":"Query"},{"location":"base/databases/#querymanager","text":"class datadog_checks.base.utils.db. QueryManager ( check , executor , queries=None , tags=None , error_handler=None ) compile_queries ( self ) execute ( self ) execute_query ( self , query )","title":"QueryManager"},{"location":"base/databases/#transformers","text":"","title":"Transformers"},{"location":"base/databases/#column","text":"class datadog_checks.base.utils.db.transform. ColumnTransformers ( ) match This is used for querying unstructured data. For example, say you want to collect the fields named foo and bar . Typically, they would be stored like: | foo | bar | | --- | --- | | 4 | 2 | and would be queried like: SELECT foo , bar FROM ... Often, you will instead find data stored in the following format: | metric | value | | ------ | ----- | | foo | 4 | | bar | 2 | and would be queried like: SELECT metric , value FROM ... In this case, the metric column stores the name with which to match on and its value is stored in a separate column. The required items modifier is a mapping of matched names to column data values. Consider the values to be exactly the same as the entries in the columns top level field. You must also define a source modifier either for this transformer itself or in the values of items (which will take precedence). The source will be treated as the value of the match. Say this is your configuration: query : SELECT source1, source2, metric FROM TABLE columns : - name : value1 type : source - name : value2 type : source - name : metric_name type : match source : value1 items : foo : name : test.foo type : gauge source : value2 bar : name : test.bar type : monotonic_gauge and the result set is: | source1 | source2 | metric | | ------- | ------- | ------ | | 1 | 2 | foo | | 3 | 4 | baz | | 5 | 6 | bar | Here's what would be submitted: foo - test.foo as a gauge with a value of 2 bar - test.bar.total as a gauge and test.bar.count as a monotonic_count , both with a value of 5 baz - nothing since it was not defined as a match item monotonic_gauge Send the result as both a gauge suffixed by .total and a monotonic_count suffixed by .count . service_check Submit a service check. The required modifier status_map is a mapping of values to statuses. Valid statuses include: OK WARNING CRITICAL UNKNOWN Any encountered values that are not defined will be sent as UNKNOWN . tag Convert a column to a tag that will be used in every subsequent submission. For example, if you named the column env and the column returned the value prod1 , all submissions from that row will be tagged by env:prod1 . This also accepts an optional modifier called boolean that when set to true will transform the result to the string true or false . So for example if you named the column alive and the result was the number 0 the tag will be alive:false . temporal_percent Send the result as percentage of time since the last check run as a rate . For example, say the result is a forever increasing counter representing the total time spent pausing for garbage collection since start up. That number by itself is quite useless, but as a percentage of time spent pausing since the previous collection interval it becomes a useful metric. There is one required parameter called scale that indicates what unit of time the result should be considered. Valid values are: second millisecond microsecond nanosecond You may also define the unit as an integer number of parts compared to seconds e.g. millisecond is equivalent to 1000 . time_elapsed Send the number of seconds elapsed from a time in the past as a gauge . For example, if the result is an instance of datetime.datetime representing 5 seconds ago, then this would submit with a value of 5 . The optional modifier format indicates what format the result is in. By default it is native , assuming the underlying library provides timestamps as datetime objects. If it does not and passes them through directly as strings, you must provide the expected timestamp format using the supported codes . Note The code %z (lower case) is not supported on Windows.","title":"Column"},{"location":"base/databases/#extra","text":"Every column transformer (except tag ) is supported at this level, the only difference being one must set a source to retrieve the desired value. So for example here: columns : - name : foo.bar type : rate extras : - name : foo.current type : gauge source : foo.bar the metric foo.current will be sent as a gauge will the value of foo.bar . class datadog_checks.base.utils.db.transform. ExtraTransformers ( ) expression This allows the evaluation of a limited subset of Python syntax and built-in functions. columns : - name : disk.total type : gauge - name : disk.used type : gauge extras : - name : disk.free expression : disk.total - disk.used submit_type : gauge For brevity, if the expression attribute exists and type does not then it is assumed the type is expression . The submit_type can be any transformer and any extra options are passed down to it. The result of every expression is stored, so in lieu of a submit_type the above example could also be written as: columns : - name : disk.total type : gauge - name : disk.used type : gauge extras : - name : free expression : disk.total - disk.used - name : disk.free type : gauge source : free The order matters though, so for example the following will fail: columns : - name : disk.total type : gauge - name : disk.used type : gauge extras : - name : disk.free type : gauge source : free - name : free expression : disk.total - disk.used since the source free does not yet exist. percent Send a percentage based on 2 sources as a gauge . The required modifiers are part and total . For example, if you have this configuration: columns : - name : disk.total type : gauge - name : disk.used type : gauge extras : - name : disk.utilized type : percent part : disk.used total : disk.total then the extra metric disk.utilized would be sent as a gauge calculated as disk.used / disk.total * 100 . If the source of total is 0 , then the submitted value will always be sent as 0 too.","title":"Extra"},{"location":"base/http/","text":"HTTP \u00b6 Whenever you need to make HTTP requests, the base class provides a convenience member that has the same interface as the popular requests library and ensures consistent behavior across all integrations. The wrapper automatically parses and uses configuration from the instance , init_config , and Agent config. Also, this is only done once during initialization and cached to reduce the overhead of every call. All you have to do is e.g.: response = self . http . get ( url ) and the wrapper will pass the right things to requests . All methods accept optional keyword arguments like stream , etc. Any method-level option will override configuration. So for example if tls_verify was set to false and you do self.http.get(url, verify=True) , then SSL certificates will be verified on that particular request. You can use the keyword argument persist to override persist_connections . There is also support for non-standard or legacy configurations with the HTTP_CONFIG_REMAPPER class attribute. For example: class MyCheck ( AgentCheck ): HTTP_CONFIG_REMAPPER = { 'disable_ssl_validation' : { 'name' : 'tls_verify' , 'default' : False , 'invert' : True , }, ... } ... Options \u00b6 Some options can be set globally in init_config (with instances taking precedence). For complete documentation of every option, see the associated configuration templates: instances init_config class datadog_checks.base.utils.http. StandardFields ( ) auth_type aws_host aws_region aws_service connect_timeout extra_headers headers kerberos_auth kerberos_cache kerberos_delegate kerberos_force_initiate kerberos_hostname kerberos_keytab kerberos_principal log_requests ntlm_domain password persist_connections proxy read_timeout skip_proxy timeout tls_ca_cert tls_cert tls_ignore_warning tls_private_key tls_verify username Future \u00b6 Support for UNIX sockets Support for configuring cookies! Since they can be set globally, per-domain, and even per-path, the configuration may be complex if not thought out adequately. We'll discuss options for what that might look like. Only our spark and cisco_aci checks currently set cookies, and that is based on code logic, not configuration.","title":"HTTP"},{"location":"base/http/#http","text":"Whenever you need to make HTTP requests, the base class provides a convenience member that has the same interface as the popular requests library and ensures consistent behavior across all integrations. The wrapper automatically parses and uses configuration from the instance , init_config , and Agent config. Also, this is only done once during initialization and cached to reduce the overhead of every call. All you have to do is e.g.: response = self . http . get ( url ) and the wrapper will pass the right things to requests . All methods accept optional keyword arguments like stream , etc. Any method-level option will override configuration. So for example if tls_verify was set to false and you do self.http.get(url, verify=True) , then SSL certificates will be verified on that particular request. You can use the keyword argument persist to override persist_connections . There is also support for non-standard or legacy configurations with the HTTP_CONFIG_REMAPPER class attribute. For example: class MyCheck ( AgentCheck ): HTTP_CONFIG_REMAPPER = { 'disable_ssl_validation' : { 'name' : 'tls_verify' , 'default' : False , 'invert' : True , }, ... } ...","title":"HTTP"},{"location":"base/http/#options","text":"Some options can be set globally in init_config (with instances taking precedence). For complete documentation of every option, see the associated configuration templates: instances init_config class datadog_checks.base.utils.http. StandardFields ( ) auth_type aws_host aws_region aws_service connect_timeout extra_headers headers kerberos_auth kerberos_cache kerberos_delegate kerberos_force_initiate kerberos_hostname kerberos_keytab kerberos_principal log_requests ntlm_domain password persist_connections proxy read_timeout skip_proxy timeout tls_ca_cert tls_cert tls_ignore_warning tls_private_key tls_verify username","title":"Options"},{"location":"base/http/#future","text":"Support for UNIX sockets Support for configuring cookies! Since they can be set globally, per-domain, and even per-path, the configuration may be complex if not thought out adequately. We'll discuss options for what that might look like. Only our spark and cisco_aci checks currently set cookies, and that is based on code logic, not configuration.","title":"Future"},{"location":"ddev/layers/","text":"What's in the box? \u00b6","title":"What's in the box?"},{"location":"ddev/layers/#whats-in-the-box","text":"","title":"What's in the box?"},{"location":"guidelines/style/","text":"Style \u00b6 These are all the checkers used by our style enforcement. black \u00b6 An opinionated formatter, like JavaScript's prettier and Golang's gofmt . isort \u00b6 A tool to sort imports lexicographically, by section, and by type. We use the 5 standard sections: __future__ , stdlib, third party, first party, and local. datadog_checks is configured as a first party namespace. flake8 \u00b6 An easy-to-use wrapper around pycodestyle and pyflakes . We select everything it provides and only ignore a few things to give precedence to other tools. bugbear \u00b6 A flake8 plugin for finding likely bugs and design problems in programs. We enable: B001 : Do not use bare except: , it also catches unexpected events like memory errors, interrupts, system exit, and so on. Prefer except Exception: . B003 : Assigning to os.environ doesn't clear the environment. Subprocesses are going to see outdated variables, in disagreement with the current process. Use os.environ.clear() or the env= argument to Popen. B006 : Do not use mutable data structures for argument defaults. All calls reuse one instance of that data structure, persisting changes between them. B007 : Loop control variable not used within the loop body. If this is intended, start the name with an underscore. B301 : Python 3 does not include .iter* methods on dictionaries. The default behavior is to return iterables. Simply remove the iter prefix from the method. For Python 2 compatibility, also prefer the Python 3 equivalent if you expect that the size of the dict to be small and bounded. The performance regression on Python 2 will be negligible and the code is going to be the clearest. Alternatively, use six.iter* . B305 : .next() is not a thing on Python 3. Use the next() builtin. For Python 2 compatibility, use six.next() . B306 : BaseException.message has been deprecated as of Python 2.6 and is removed in Python 3. Use str(e) to access the user-readable message. Use e.args to access arguments passed to the exception. B902 : Invalid first argument used for method. Use self for instance methods, and cls for class methods. logging-format \u00b6 A flake8 plugin for ensuring a consistent logging format. We enable: G001 : Logging statements should not use string.format() for their first argument G002 : Logging statements should not use % formatting for their first argument G003 : Logging statements should not use + concatenation for their first argument G004 : Logging statements should not use f\"...\" for their first argument (only in Python 3.6+) G010 : Logging statements should not use warn (use warning instead) G100 : Logging statements should not use extra arguments unless whitelisted G201 : Logging statements should not use error(..., exc_info=True) (use exception(...) instead) G202 : Logging statements should not use redundant exc_info=True in exception Mypy \u00b6 A type checker allowing a mix of dynamic and static typing. This is optional for now.","title":"Style"},{"location":"guidelines/style/#style","text":"These are all the checkers used by our style enforcement.","title":"Style"},{"location":"guidelines/style/#black","text":"An opinionated formatter, like JavaScript's prettier and Golang's gofmt .","title":"black"},{"location":"guidelines/style/#isort","text":"A tool to sort imports lexicographically, by section, and by type. We use the 5 standard sections: __future__ , stdlib, third party, first party, and local. datadog_checks is configured as a first party namespace.","title":"isort"},{"location":"guidelines/style/#flake8","text":"An easy-to-use wrapper around pycodestyle and pyflakes . We select everything it provides and only ignore a few things to give precedence to other tools.","title":"flake8"},{"location":"guidelines/style/#bugbear","text":"A flake8 plugin for finding likely bugs and design problems in programs. We enable: B001 : Do not use bare except: , it also catches unexpected events like memory errors, interrupts, system exit, and so on. Prefer except Exception: . B003 : Assigning to os.environ doesn't clear the environment. Subprocesses are going to see outdated variables, in disagreement with the current process. Use os.environ.clear() or the env= argument to Popen. B006 : Do not use mutable data structures for argument defaults. All calls reuse one instance of that data structure, persisting changes between them. B007 : Loop control variable not used within the loop body. If this is intended, start the name with an underscore. B301 : Python 3 does not include .iter* methods on dictionaries. The default behavior is to return iterables. Simply remove the iter prefix from the method. For Python 2 compatibility, also prefer the Python 3 equivalent if you expect that the size of the dict to be small and bounded. The performance regression on Python 2 will be negligible and the code is going to be the clearest. Alternatively, use six.iter* . B305 : .next() is not a thing on Python 3. Use the next() builtin. For Python 2 compatibility, use six.next() . B306 : BaseException.message has been deprecated as of Python 2.6 and is removed in Python 3. Use str(e) to access the user-readable message. Use e.args to access arguments passed to the exception. B902 : Invalid first argument used for method. Use self for instance methods, and cls for class methods.","title":"bugbear"},{"location":"guidelines/style/#logging-format","text":"A flake8 plugin for ensuring a consistent logging format. We enable: G001 : Logging statements should not use string.format() for their first argument G002 : Logging statements should not use % formatting for their first argument G003 : Logging statements should not use + concatenation for their first argument G004 : Logging statements should not use f\"...\" for their first argument (only in Python 3.6+) G010 : Logging statements should not use warn (use warning instead) G100 : Logging statements should not use extra arguments unless whitelisted G201 : Logging statements should not use error(..., exc_info=True) (use exception(...) instead) G202 : Logging statements should not use redundant exc_info=True in exception","title":"logging-format"},{"location":"guidelines/style/#mypy","text":"A type checker allowing a mix of dynamic and static typing. This is optional for now.","title":"Mypy"}]}